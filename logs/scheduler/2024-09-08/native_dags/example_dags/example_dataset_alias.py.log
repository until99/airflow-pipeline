[2024-09-08T15:27:43.494-0300] {processor.py:186} INFO - Started process (PID=32122) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:27:43.495-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:27:43.497-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:27:43.496-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:27:43.584-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:27:43.595-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:27:43.595-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:27:43.606-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:27:43.606-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:27:43.608-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:27:43.608-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:27:43.609-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:27:43.608-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:27:43.609-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:27:43.609-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:27:43.627-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.137 seconds
[2024-09-08T15:28:37.650-0300] {processor.py:186} INFO - Started process (PID=32285) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:28:37.652-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:28:37.653-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:28:37.653-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:28:37.670-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:28:37.687-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:28:37.686-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:28:37.701-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:28:37.701-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:28:37.703-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:28:37.703-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:28:37.704-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:28:37.704-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:28:37.705-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:28:37.705-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:28:37.723-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.078 seconds
[2024-09-08T15:29:29.465-0300] {processor.py:186} INFO - Started process (PID=32391) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:29:29.465-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:29:29.467-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:29:29.467-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:29:29.482-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:29:29.495-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:29:29.495-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:29:29.509-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:29:29.509-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:29:29.511-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:29:29.511-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:29:29.512-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:29:29.511-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:29:29.512-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:29:29.512-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:29:29.531-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.070 seconds
[2024-09-08T15:30:20.519-0300] {processor.py:186} INFO - Started process (PID=32641) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:30:20.520-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:30:20.521-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:30:20.521-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:30:20.537-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:30:20.553-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:30:20.553-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:30:20.567-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:30:20.567-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:30:20.569-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:30:20.569-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:30:20.569-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:30:20.569-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:30:20.570-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:30:20.570-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:30:20.590-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.075 seconds
[2024-09-08T15:31:32.651-0300] {processor.py:186} INFO - Started process (PID=32839) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:31:32.652-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:31:32.653-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:31:32.653-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:31:32.671-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:31:32.686-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:31:32.686-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:31:32.702-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:31:32.701-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:31:32.703-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:31:32.703-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:31:32.704-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:31:32.704-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:31:32.706-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:31:32.705-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:31:32.729-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.083 seconds
[2024-09-08T15:32:45.587-0300] {processor.py:186} INFO - Started process (PID=33063) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:32:45.594-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:32:45.595-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:32:45.595-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:32:45.613-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:32:45.629-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:32:45.629-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:32:45.646-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:32:45.646-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:32:45.649-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:32:45.649-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:32:45.650-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:32:45.650-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:32:45.651-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:32:45.650-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:32:45.671-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.088 seconds
[2024-09-08T15:33:35.812-0300] {processor.py:186} INFO - Started process (PID=33284) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:33:35.813-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:33:35.813-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:33:35.813-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:33:35.830-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:33:35.845-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:33:35.845-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:33:35.861-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:33:35.861-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:33:35.863-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:33:35.862-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:33:35.863-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:33:35.863-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:33:35.864-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:33:35.864-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:33:35.885-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.076 seconds
[2024-09-08T15:34:50.056-0300] {processor.py:186} INFO - Started process (PID=33608) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:34:50.056-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:34:50.057-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:34:50.057-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:34:50.073-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:34:50.086-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:34:50.086-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:34:50.100-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:34:50.100-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:34:50.103-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:34:50.102-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:34:50.103-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:34:50.103-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:34:50.104-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:34:50.104-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:34:50.123-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.071 seconds
[2024-09-08T15:35:56.144-0300] {processor.py:186} INFO - Started process (PID=33919) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:35:56.145-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:35:56.146-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:35:56.146-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:35:56.162-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:35:56.177-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:35:56.177-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:35:56.190-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:35:56.190-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:35:56.191-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:35:56.191-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:35:56.192-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:35:56.192-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:35:56.192-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:35:56.192-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:35:56.212-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.071 seconds
[2024-09-08T15:36:51.047-0300] {processor.py:186} INFO - Started process (PID=34049) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:36:51.048-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:36:51.049-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:36:51.049-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:36:51.066-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:36:51.080-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:36:51.080-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:36:51.095-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:36:51.095-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:36:51.096-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:36:51.096-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:36:51.097-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:36:51.097-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:36:51.098-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:36:51.098-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:36:51.117-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.073 seconds
[2024-09-08T15:37:46.358-0300] {processor.py:186} INFO - Started process (PID=34236) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:37:46.359-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:37:46.360-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:37:46.360-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:37:46.375-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:37:46.389-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:37:46.389-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:37:46.404-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:37:46.404-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:37:46.405-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:37:46.405-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:37:46.407-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:37:46.407-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:37:46.408-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:37:46.408-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:37:46.426-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.071 seconds
[2024-09-08T15:39:01.334-0300] {processor.py:186} INFO - Started process (PID=34645) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:39:01.335-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:39:01.336-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:01.336-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:39:01.350-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:39:01.363-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:01.363-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:39:01.376-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:01.376-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:39:01.377-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:01.377-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:39:01.378-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:01.378-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:39:01.378-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:01.378-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:39:01.398-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.067 seconds
[2024-09-08T15:39:53.840-0300] {processor.py:186} INFO - Started process (PID=34960) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:39:53.850-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:39:53.852-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:53.852-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:39:53.868-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:39:53.882-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:53.882-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:39:53.898-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:53.898-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:39:53.900-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:53.899-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:39:53.900-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:53.900-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:39:53.901-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:39:53.901-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:39:53.920-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.084 seconds
[2024-09-08T15:40:46.873-0300] {processor.py:186} INFO - Started process (PID=35314) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:40:46.874-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:40:46.875-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:40:46.875-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:40:46.890-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:40:46.973-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:40:46.973-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:40:46.986-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:40:46.985-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:40:46.988-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:40:46.987-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:40:46.988-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:40:46.988-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:40:46.989-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:40:46.989-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:40:47.009-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.139 seconds
[2024-09-08T15:41:38.691-0300] {processor.py:186} INFO - Started process (PID=35532) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:41:38.762-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:41:38.764-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:41:38.764-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:41:38.781-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:41:38.796-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:41:38.796-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:41:38.811-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:41:38.811-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:41:38.813-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:41:38.812-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:41:38.813-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:41:38.813-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:41:38.814-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:41:38.814-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:41:38.833-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.146 seconds
[2024-09-08T15:42:55.665-0300] {processor.py:186} INFO - Started process (PID=35764) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:42:55.666-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:42:55.668-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:42:55.667-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:42:55.683-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:42:55.696-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:42:55.696-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:42:55.710-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:42:55.710-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:42:55.712-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:42:55.711-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:42:55.712-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:42:55.712-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:42:55.713-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:42:55.713-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:42:55.733-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.071 seconds
[2024-09-08T15:43:49.708-0300] {processor.py:186} INFO - Started process (PID=35957) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:43:49.709-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:43:49.710-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:43:49.710-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:43:49.727-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:43:49.740-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:43:49.740-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:43:49.755-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:43:49.755-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:43:49.756-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:43:49.756-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:43:49.757-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:43:49.757-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:43:49.758-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:43:49.758-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:43:49.776-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.071 seconds
[2024-09-08T15:44:42.678-0300] {processor.py:186} INFO - Started process (PID=36177) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:44:42.679-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:44:42.681-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:44:42.681-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:44:42.704-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:44:42.723-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:44:42.722-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:44:42.740-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:44:42.740-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:44:42.742-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:44:42.742-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:44:42.743-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:44:42.743-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:44:42.744-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:44:42.744-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:44:42.771-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.100 seconds
[2024-09-08T15:45:58.328-0300] {processor.py:186} INFO - Started process (PID=36386) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:45:58.329-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:45:58.331-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:45:58.331-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:45:58.357-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:45:58.381-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:45:58.380-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:45:58.401-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:45:58.401-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:45:58.405-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:45:58.404-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:45:58.407-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:45:58.407-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:45:58.408-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:45:58.408-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:45:58.437-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.113 seconds
[2024-09-08T15:46:51.264-0300] {processor.py:186} INFO - Started process (PID=36602) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:46:51.265-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:46:51.266-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:46:51.266-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:46:51.281-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:46:51.295-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:46:51.295-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:46:51.308-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:46:51.308-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:46:51.310-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:46:51.310-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:46:51.311-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:46:51.311-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:46:51.311-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:46:51.311-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:46:51.331-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.071 seconds
[2024-09-08T15:47:44.574-0300] {processor.py:186} INFO - Started process (PID=36768) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:47:44.575-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:47:44.576-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:47:44.576-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:47:44.592-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:47:44.606-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:47:44.606-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:47:44.620-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:47:44.620-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:47:44.624-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:47:44.623-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:47:44.625-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:47:44.625-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:47:44.626-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:47:44.625-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:47:44.648-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.078 seconds
[2024-09-08T15:48:41.506-0300] {processor.py:186} INFO - Started process (PID=37112) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:48:41.507-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:48:41.509-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:48:41.508-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:48:41.525-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:48:41.540-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:48:41.540-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:48:41.556-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:48:41.556-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:48:41.558-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:48:41.557-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:48:41.558-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:48:41.558-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:48:41.559-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:48:41.559-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:48:41.578-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.076 seconds
[2024-09-08T15:49:35.067-0300] {processor.py:186} INFO - Started process (PID=37666) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:49:35.068-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:49:35.071-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:49:35.070-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:49:35.101-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:49:35.243-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:49:35.243-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:49:35.252-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:49:35.252-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T15:49:35.260-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:49:35.260-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:49:35.261-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:49:35.260-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:49:35.262-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:49:35.262-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:49:35.263-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:49:35.263-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:49:35.289-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.231 seconds
[2024-09-08T15:50:27.355-0300] {processor.py:186} INFO - Started process (PID=38412) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:50:27.356-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:50:27.358-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:50:27.357-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:50:27.375-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:50:27.467-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:50:27.467-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:50:27.474-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:50:27.474-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T15:50:27.475-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:50:27.475-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T15:50:27.480-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:50:27.480-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:50:27.481-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:50:27.480-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:50:27.481-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:50:27.481-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:50:27.483-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:50:27.483-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:50:27.505-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.154 seconds
[2024-09-08T15:51:19.208-0300] {processor.py:186} INFO - Started process (PID=38935) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:51:19.208-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:51:19.210-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:51:19.210-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:51:19.226-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:51:19.240-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:51:19.240-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:51:19.256-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:51:19.256-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:51:19.257-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:51:19.257-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:51:19.258-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:51:19.258-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:51:19.260-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:51:19.260-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:51:19.279-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.075 seconds
[2024-09-08T15:52:35.335-0300] {processor.py:186} INFO - Started process (PID=39337) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:52:35.336-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:52:35.337-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:52:35.337-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:52:35.354-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:52:35.371-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:52:35.371-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:52:35.386-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:52:35.386-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:52:35.387-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:52:35.387-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:52:35.388-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:52:35.388-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:52:35.389-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:52:35.389-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:52:35.410-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.079 seconds
[2024-09-08T15:53:26.341-0300] {processor.py:186} INFO - Started process (PID=40010) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:53:26.342-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:53:26.343-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:53:26.343-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:53:26.359-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:53:26.374-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:53:26.374-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:53:26.388-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:53:26.388-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:53:26.390-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:53:26.390-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:53:26.391-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:53:26.391-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:53:26.392-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:53:26.392-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:53:26.412-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.074 seconds
[2024-09-08T15:54:39.733-0300] {processor.py:186} INFO - Started process (PID=41097) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:54:39.742-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:54:39.744-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:54:39.743-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:54:39.760-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:54:39.773-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:54:39.773-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:54:39.786-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:54:39.786-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:54:39.787-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:54:39.787-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:54:39.788-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:54:39.788-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:54:39.789-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:54:39.789-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:54:39.808-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.078 seconds
[2024-09-08T15:55:33.657-0300] {processor.py:186} INFO - Started process (PID=41287) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:55:33.658-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:55:33.660-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:55:33.659-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:55:33.680-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:55:33.702-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:55:33.701-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:55:33.722-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:55:33.722-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:55:33.725-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:55:33.724-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:55:33.725-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:55:33.725-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:55:33.726-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:55:33.726-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:55:33.751-0300] {processor.py:208} INFO - Processing /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py took 0.097 seconds
[2024-09-08T15:56:43.316-0300] {processor.py:186} INFO - Started process (PID=41910) to work on /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:56:43.316-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:56:43.318-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.318-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:56:43.335-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:56:43.350-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.350-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:56:43.359-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.359-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T15:56:43.360-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.360-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T15:56:43.360-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.360-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T15:56:43.361-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.361-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T15:56:43.367-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.367-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:56:43.368-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.368-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:56:43.368-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.368-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:56:43.369-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.369-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:56:43.457-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.456-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T15:56:43.458-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.458-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T15:56:43.459-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.459-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T15:56:43.460-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.460-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T15:56:43.461-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:56:43.461-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:56:43.461-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/share/pipx/venvs/apache-airflow/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T15:58:08.315-0300] {processor.py:186} INFO - Started process (PID=42923) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:58:08.316-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T15:58:08.319-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.317-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:58:08.332-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T15:58:08.436-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.436-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:58:08.443-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.443-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T15:58:08.444-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.443-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T15:58:08.444-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.444-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T15:58:08.444-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.444-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T15:58:08.450-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.449-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T15:58:08.450-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.450-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T15:58:08.451-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.450-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T15:58:08.451-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.451-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T15:58:08.537-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.536-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T15:58:08.538-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.538-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T15:58:08.539-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.538-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T15:58:08.540-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.539-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T15:58:08.540-0300] {logging_mixin.py:190} INFO - [2024-09-08T15:58:08.540-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T15:58:08.541-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:00:21.620-0300] {processor.py:186} INFO - Started process (PID=44166) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:00:21.621-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:00:21.622-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:21.622-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:00:21.641-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:00:21.761-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:21.760-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:00:21.768-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:21.768-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:00:21.769-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:21.769-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:00:21.769-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:21.769-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:00:21.770-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:21.770-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:00:21.777-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:21.777-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:00:21.778-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:21.778-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:00:21.779-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:21.778-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:00:21.779-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:21.779-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:00:22.076-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:22.074-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:00:22.078-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:22.077-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:00:22.079-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:22.079-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:00:22.080-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:22.080-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:00:22.081-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:00:22.081-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:00:22.082-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:03:44.635-0300] {processor.py:186} INFO - Started process (PID=46183) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:03:44.636-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:03:44.638-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:44.638-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:03:44.659-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:03:44.777-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:44.777-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:03:44.788-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:44.788-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:03:44.789-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:44.789-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:03:44.790-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:44.789-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:03:44.790-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:44.790-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:03:44.796-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:44.795-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:03:44.796-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:44.796-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:03:44.796-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:44.796-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:03:44.797-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:44.797-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:03:45.197-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:45.195-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:03:45.198-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:45.197-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:03:45.199-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:45.198-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:03:45.199-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:45.199-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:03:45.200-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:03:45.200-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:03:45.201-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:06:52.305-0300] {processor.py:186} INFO - Started process (PID=47972) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:06:52.310-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:06:52.311-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.311-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:06:52.326-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:06:52.502-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.502-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:06:52.509-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.509-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:06:52.510-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.509-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:06:52.510-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.510-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:06:52.510-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.510-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:06:52.516-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.516-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:06:52.517-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.517-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:06:52.517-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.517-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:06:52.517-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.517-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:06:52.642-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.641-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:06:52.644-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.643-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:06:52.645-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.644-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:06:52.645-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.645-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:06:52.646-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:06:52.646-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:06:52.647-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:10:02.744-0300] {processor.py:186} INFO - Started process (PID=49832) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:10:02.744-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:10:02.746-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:02.746-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:10:02.761-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:10:02.904-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:02.904-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:10:02.912-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:02.912-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:10:02.912-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:02.912-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:10:02.913-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:02.912-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:10:02.913-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:02.913-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:10:02.918-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:02.918-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:10:02.918-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:02.918-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:10:02.919-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:02.919-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:10:02.919-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:02.919-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:10:03.348-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:03.347-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:10:03.349-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:03.349-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:10:03.350-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:03.350-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:10:03.351-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:03.351-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:10:03.351-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:10:03.351-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:10:03.352-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:13:03.199-0300] {processor.py:186} INFO - Started process (PID=51374) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:13:03.200-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:13:03.201-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.201-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:13:03.220-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:13:03.312-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.312-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:13:03.322-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.322-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:13:03.322-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.322-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:13:03.323-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.323-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:13:03.323-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.323-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:13:03.331-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.331-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:13:03.331-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.331-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:13:03.332-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.332-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:13:03.332-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.332-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:13:03.810-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.807-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:13:03.812-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.811-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:13:03.814-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.813-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:13:03.816-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.815-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:13:03.817-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:13:03.817-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:13:03.818-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:14:52.317-0300] {processor.py:186} INFO - Started process (PID=52406) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:14:52.317-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:14:52.319-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.318-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:14:52.334-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:14:52.428-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.428-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:14:52.436-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.436-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:14:52.437-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.437-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:14:52.437-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.437-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:14:52.438-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.438-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:14:52.443-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.443-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:14:52.444-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.444-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:14:52.444-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.444-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:14:52.444-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.444-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:14:52.647-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.645-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:14:52.648-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.648-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:14:52.649-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.649-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:14:52.650-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.650-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:14:52.651-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:14:52.650-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:14:52.651-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:16:11.411-0300] {processor.py:186} INFO - Started process (PID=53016) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:16:11.412-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:16:11.413-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.413-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:16:11.427-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:16:11.499-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.499-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:16:11.507-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.506-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:16:11.507-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.507-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:16:11.508-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.507-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:16:11.508-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.508-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:16:11.514-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.513-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:16:11.514-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.514-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:16:11.514-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.514-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:16:11.515-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.515-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:16:11.750-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.748-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:16:11.751-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.750-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:16:11.752-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.751-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:16:11.753-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.752-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:16:11.753-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:16:11.753-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:16:11.754-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:17:25.984-0300] {processor.py:186} INFO - Started process (PID=53582) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:17:25.985-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:17:25.986-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:25.986-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:17:26.000-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:17:26.072-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.072-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:17:26.080-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.080-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:17:26.080-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.080-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:17:26.081-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.080-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:17:26.081-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.081-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:17:26.086-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.086-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:17:26.087-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.086-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:17:26.087-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.087-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:17:26.087-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.087-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:17:26.421-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.419-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:17:26.422-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.422-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:17:26.423-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.423-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:17:26.424-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.424-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:17:26.425-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:17:26.425-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:17:26.425-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:18:40.392-0300] {processor.py:186} INFO - Started process (PID=54319) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:18:40.393-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:18:40.394-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.394-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:18:40.411-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:18:40.506-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.506-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:18:40.514-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.514-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:18:40.515-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.515-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:18:40.515-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.515-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:18:40.516-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.516-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:18:40.523-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.523-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:18:40.524-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.523-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:18:40.524-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.524-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:18:40.524-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.524-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:18:40.737-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.732-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:18:40.741-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.739-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:18:40.743-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.742-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:18:40.748-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.744-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:18:40.749-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:18:40.749-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:18:40.750-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:20:03.694-0300] {processor.py:186} INFO - Started process (PID=55196) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:20:03.694-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:20:03.695-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:03.695-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:20:03.711-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:20:03.780-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:03.780-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:20:03.788-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:03.788-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:20:03.788-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:03.788-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:20:03.789-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:03.789-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:20:03.789-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:03.789-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:20:03.795-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:03.795-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:20:03.795-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:03.795-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:20:03.796-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:03.796-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:20:03.796-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:03.796-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:20:04.297-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:04.296-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:20:04.298-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:04.298-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:20:04.299-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:04.298-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:20:04.300-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:04.299-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:20:04.300-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:20:04.300-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:20:04.301-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:21:24.207-0300] {processor.py:186} INFO - Started process (PID=56755) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:21:24.208-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:21:24.209-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.208-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:21:24.228-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:21:24.337-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.336-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:21:24.350-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.350-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:21:24.351-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.350-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:21:24.351-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.351-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:21:24.352-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.351-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:21:24.360-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.360-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:21:24.361-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.361-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:21:24.362-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.362-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:21:24.362-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.362-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:21:24.533-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.531-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:21:24.535-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.534-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:21:24.537-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.536-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:21:24.539-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.538-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:21:24.540-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:21:24.539-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:21:24.541-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:22:57.324-0300] {processor.py:186} INFO - Started process (PID=58094) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:22:57.325-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:22:57.326-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.325-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:22:57.341-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:22:57.421-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.421-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:22:57.431-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.431-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:22:57.432-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.431-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:22:57.432-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.432-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:22:57.432-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.432-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:22:57.438-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.438-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:22:57.439-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.439-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:22:57.439-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.439-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:22:57.439-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.439-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:22:57.451-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.449-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:22:57.452-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.451-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:22:57.452-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.452-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:22:57.453-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.453-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:22:57.454-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:22:57.454-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:22:57.455-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:24:13.983-0300] {processor.py:186} INFO - Started process (PID=58845) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:24:13.983-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:24:13.984-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:13.984-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:24:14.000-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:24:14.074-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.074-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:24:14.081-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.081-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:24:14.082-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.082-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:24:14.082-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.082-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:24:14.082-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.082-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:24:14.088-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.088-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:24:14.089-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.089-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:24:14.091-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.089-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:24:14.092-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.092-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:24:14.521-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.520-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:24:14.522-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.522-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:24:14.523-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.523-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:24:14.524-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.524-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:24:14.525-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:24:14.524-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:24:14.525-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('producer', 'dataset_s3_bucket_producer'), ('dataset', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:32:11.138-0300] {processor.py:186} INFO - Started process (PID=65882) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:32:11.139-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:32:11.141-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.141-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:32:11.156-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:32:11.231-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.231-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:32:11.239-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.239-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:32:11.239-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.239-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:32:11.240-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.239-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:32:11.240-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.240-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:32:11.246-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.246-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:32:11.247-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.246-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:32:11.247-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.247-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:32:11.247-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.247-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:32:11.466-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.464-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:32:11.468-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.467-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:32:11.469-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.469-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:32:11.471-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.470-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:32:11.471-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:32:11.471-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:32:11.472-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:33:55.977-0300] {processor.py:186} INFO - Started process (PID=67333) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:33:55.978-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:33:55.980-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:55.979-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:33:55.995-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:33:56.069-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.069-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:33:56.076-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.076-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:33:56.076-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.076-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:33:56.077-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.077-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:33:56.077-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.077-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:33:56.083-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.082-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:33:56.083-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.083-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:33:56.083-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.083-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:33:56.084-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.084-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:33:56.334-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.333-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:33:56.335-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.335-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:33:56.336-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.336-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:33:56.337-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.337-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:33:56.338-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:33:56.338-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:33:56.339-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:36:18.397-0300] {processor.py:186} INFO - Started process (PID=69355) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:36:18.398-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:36:18.399-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.399-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:36:18.413-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:36:18.484-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.484-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:36:18.491-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.491-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:36:18.491-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.491-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:36:18.492-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.491-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:36:18.492-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.492-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:36:18.497-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.497-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:36:18.498-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.497-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:36:18.498-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.498-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:36:18.498-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.498-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:36:18.869-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.868-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:36:18.870-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.870-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:36:18.871-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.871-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:36:18.872-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.872-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:36:18.873-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:36:18.873-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:36:18.873-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:39:50.871-0300] {processor.py:186} INFO - Started process (PID=72257) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:39:50.873-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:39:50.875-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:50.875-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:39:50.892-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:39:50.963-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:50.963-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:39:50.970-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:50.970-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:39:50.971-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:50.971-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:39:50.971-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:50.971-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:39:50.972-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:50.972-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:39:50.977-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:50.977-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:39:50.977-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:50.977-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:39:50.978-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:50.978-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:39:50.978-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:50.978-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:39:51.375-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:51.374-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:39:51.376-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:51.376-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:39:51.377-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:51.377-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:39:51.378-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:51.378-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:39:51.379-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:39:51.378-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:39:51.379-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:43:22.646-0300] {processor.py:186} INFO - Started process (PID=75198) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:43:22.647-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:43:22.648-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:22.648-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:43:22.663-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:43:22.731-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:22.731-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:43:22.738-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:22.738-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:43:22.739-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:22.739-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:43:22.739-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:22.739-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:43:22.739-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:22.739-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:43:22.745-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:22.745-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:43:22.745-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:22.745-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:43:22.746-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:22.746-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:43:22.746-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:22.746-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:43:23.116-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:23.114-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:43:23.117-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:23.116-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:43:23.117-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:23.117-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:43:23.118-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:23.118-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:43:23.119-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:43:23.119-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:43:23.119-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:46:57.835-0300] {processor.py:186} INFO - Started process (PID=78170) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:46:57.836-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:46:57.837-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:57.837-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:46:57.851-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:46:57.919-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:57.919-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:46:57.926-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:57.925-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:46:57.926-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:57.926-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:46:57.926-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:57.926-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:46:57.927-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:57.927-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:46:57.932-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:57.932-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:46:57.932-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:57.932-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:46:57.933-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:57.933-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:46:57.933-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:57.933-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:46:58.051-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:58.050-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:46:58.052-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:58.052-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:46:58.053-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:58.053-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:46:58.054-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:58.053-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:46:58.054-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:46:58.054-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:46:58.055-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:50:28.854-0300] {processor.py:186} INFO - Started process (PID=81067) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:50:29.023-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:50:29.025-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.025-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:50:29.040-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:50:29.107-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.107-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:50:29.113-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.113-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:50:29.114-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.114-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:50:29.114-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.114-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:50:29.114-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.114-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:50:29.119-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.119-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:50:29.120-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.120-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:50:29.120-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.120-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:50:29.121-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.120-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:50:29.425-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.424-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:50:29.426-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.426-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:50:29.427-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.427-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:50:29.428-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.428-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:50:29.429-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:50:29.429-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:50:29.429-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:53:58.503-0300] {processor.py:186} INFO - Started process (PID=83977) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:53:58.504-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:53:58.506-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.506-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:53:58.527-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:53:58.640-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.640-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:53:58.654-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.654-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:53:58.655-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.655-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:53:58.656-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.656-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:53:58.657-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.656-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:53:58.668-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.668-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:53:58.669-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.669-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:53:58.670-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.670-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:53:58.671-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.670-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:53:58.770-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.769-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:53:58.772-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.771-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:53:58.773-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.772-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:53:58.774-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.773-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:53:58.774-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:53:58.774-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:53:58.775-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:57:32.780-0300] {processor.py:186} INFO - Started process (PID=87040) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:57:32.780-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T16:57:32.782-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:32.781-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:57:32.795-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T16:57:32.865-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:32.865-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:57:32.872-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:32.872-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T16:57:32.872-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:32.872-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T16:57:32.873-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:32.873-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T16:57:32.873-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:32.873-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T16:57:32.879-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:32.879-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T16:57:32.880-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:32.879-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T16:57:32.881-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:32.881-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T16:57:32.881-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:32.881-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T16:57:33.040-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:33.038-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:57:33.041-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:33.040-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:57:33.042-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:33.041-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:57:33.043-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:33.042-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T16:57:33.043-0300] {logging_mixin.py:190} INFO - [2024-09-08T16:57:33.043-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T16:57:33.044-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:00:57.259-0300] {processor.py:186} INFO - Started process (PID=89690) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:00:57.260-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:00:57.261-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.261-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:00:57.275-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:00:57.348-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.348-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:00:57.356-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.356-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:00:57.356-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.356-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:00:57.357-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.357-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:00:57.357-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.357-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:00:57.363-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.363-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:00:57.363-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.363-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:00:57.364-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.363-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:00:57.364-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.364-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:00:57.629-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.627-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:00:57.630-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.629-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:00:57.630-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.630-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:00:57.631-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.631-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:00:57.632-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:00:57.632-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:00:57.632-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:04:24.019-0300] {processor.py:186} INFO - Started process (PID=92406) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:04:24.019-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:04:24.021-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.020-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:04:24.035-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:04:24.104-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.104-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:04:24.112-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.112-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:04:24.113-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.113-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:04:24.113-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.113-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:04:24.113-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.113-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:04:24.119-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.118-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:04:24.119-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.119-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:04:24.119-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.119-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:04:24.120-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.120-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:04:24.457-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.456-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:04:24.458-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.458-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:04:24.459-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.459-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:04:24.460-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.460-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:04:24.460-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:04:24.460-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:04:24.461-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:07:51.881-0300] {processor.py:186} INFO - Started process (PID=95123) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:07:51.881-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:07:51.883-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:51.882-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:07:51.897-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:07:51.967-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:51.967-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:07:51.974-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:51.974-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:07:51.974-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:51.974-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:07:51.975-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:51.975-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:07:51.975-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:51.975-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:07:51.980-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:51.980-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:07:51.981-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:51.981-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:07:51.981-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:51.981-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:07:51.982-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:51.982-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:07:52.029-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:52.028-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:07:52.030-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:52.030-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:07:52.031-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:52.031-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:07:52.032-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:52.032-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:07:52.032-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:07:52.032-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:07:52.033-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:11:22.117-0300] {processor.py:186} INFO - Started process (PID=97892) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:11:22.118-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:11:22.119-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.119-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:11:22.134-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:11:22.207-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.207-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:11:22.214-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.214-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:11:22.215-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.214-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:11:22.215-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.215-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:11:22.215-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.215-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:11:22.221-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.221-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:11:22.221-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.221-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:11:22.222-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.222-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:11:22.222-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.222-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:11:22.488-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.487-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:11:22.489-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.489-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:11:22.490-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.490-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:11:22.491-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.490-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:11:22.491-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:11:22.491-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:11:22.492-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:14:51.878-0300] {processor.py:186} INFO - Started process (PID=100630) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:14:51.878-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:14:51.879-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:51.879-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:14:51.894-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:14:51.971-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:51.971-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:14:51.978-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:51.978-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:14:51.979-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:51.979-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:14:51.979-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:51.979-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:14:51.980-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:51.979-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:14:51.986-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:51.985-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:14:51.986-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:51.986-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:14:51.986-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:51.986-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:14:51.987-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:51.987-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:14:52.058-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:52.057-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:14:52.059-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:52.059-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:14:52.060-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:52.060-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:14:52.061-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:52.061-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:14:52.062-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:14:52.062-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:14:52.062-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:18:21.787-0300] {processor.py:186} INFO - Started process (PID=103421) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:18:21.787-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:18:21.789-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:21.788-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:18:21.802-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:18:21.870-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:21.870-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:18:21.877-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:21.877-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:18:21.877-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:21.877-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:18:21.877-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:21.877-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:18:21.878-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:21.878-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:18:21.883-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:21.883-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:18:21.883-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:21.883-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:18:21.884-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:21.884-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:18:21.884-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:21.884-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:18:22.310-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:22.308-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:18:22.311-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:22.311-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:18:22.312-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:22.312-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:18:22.313-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:22.313-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:18:22.313-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:18:22.313-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:18:22.314-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:21:53.720-0300] {processor.py:186} INFO - Started process (PID=106254) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:21:53.722-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:21:53.724-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:53.723-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:21:53.738-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:21:53.807-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:53.806-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:21:53.814-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:53.814-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:21:53.815-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:53.815-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:21:53.815-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:53.815-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:21:53.815-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:53.815-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:21:53.821-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:53.821-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:21:53.821-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:53.821-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:21:53.822-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:53.821-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:21:53.822-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:53.822-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:21:54.040-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:54.039-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:21:54.042-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:54.041-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:21:54.042-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:54.042-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:21:54.043-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:54.043-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:21:54.044-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:21:54.044-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:21:54.044-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:25:20.455-0300] {processor.py:186} INFO - Started process (PID=109012) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:25:20.456-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:25:20.457-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.457-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:25:20.471-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:25:20.538-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.538-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:25:20.546-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.546-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:25:20.546-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.546-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:25:20.547-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.547-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:25:20.547-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.547-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:25:20.553-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.552-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:25:20.553-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.553-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:25:20.553-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.553-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:25:20.554-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.554-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:25:20.643-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.642-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:25:20.644-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.644-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:25:20.645-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.645-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:25:20.646-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.646-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:25:20.647-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:25:20.647-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:25:20.647-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:28:45.651-0300] {processor.py:186} INFO - Started process (PID=111770) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:28:45.662-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:28:45.664-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.664-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:28:45.679-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:28:45.747-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.747-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:28:45.755-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.755-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:28:45.755-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.755-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:28:45.756-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.756-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:28:45.756-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.756-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:28:45.762-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.761-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:28:45.762-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.762-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:28:45.762-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.762-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:28:45.763-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.763-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:28:45.956-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.954-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:28:45.957-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.957-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:28:45.958-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.957-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:28:45.959-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.958-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:28:45.959-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:28:45.959-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:28:45.960-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:31:56.347-0300] {processor.py:186} INFO - Started process (PID=114279) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:31:56.348-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:31:56.349-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.349-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:31:56.364-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:31:56.434-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.434-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:31:56.443-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.443-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:31:56.443-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.443-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:31:56.444-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.443-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:31:56.444-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.444-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:31:56.451-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.451-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:31:56.452-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.452-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:31:56.452-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.452-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:31:56.453-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.452-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:31:56.700-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.698-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:31:56.701-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.701-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:31:56.702-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.702-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:31:56.703-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.702-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:31:56.703-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:31:56.703-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:31:56.704-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:35:19.128-0300] {processor.py:186} INFO - Started process (PID=116968) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:35:19.129-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:35:19.130-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.130-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:35:19.145-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:35:19.216-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.216-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:35:19.223-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.223-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:35:19.223-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.223-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:35:19.224-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.223-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:35:19.224-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.224-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:35:19.229-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.229-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:35:19.229-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.229-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:35:19.230-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.230-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:35:19.230-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.230-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:35:19.353-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.352-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:35:19.354-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.354-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:35:19.355-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.355-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:35:19.356-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.355-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:35:19.356-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:35:19.356-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:35:19.357-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:38:25.519-0300] {processor.py:186} INFO - Started process (PID=119384) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:38:25.520-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:38:25.521-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.521-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:38:25.535-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:38:25.605-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.604-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:38:25.611-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.611-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:38:25.612-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.612-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:38:25.612-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.612-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:38:25.612-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.612-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:38:25.618-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.617-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:38:25.618-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.618-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:38:25.618-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.618-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:38:25.619-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.619-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:38:25.885-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.883-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:38:25.886-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.885-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:38:25.886-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.886-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:38:25.887-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.887-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:38:25.888-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:38:25.888-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:38:25.889-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:41:40.050-0300] {processor.py:186} INFO - Started process (PID=122044) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:41:40.051-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:41:40.053-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.052-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:41:40.067-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:41:40.137-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.137-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:41:40.144-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.144-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:41:40.144-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.144-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:41:40.145-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.145-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:41:40.145-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.145-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:41:40.150-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.150-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:41:40.151-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.151-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:41:40.151-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.151-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:41:40.151-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.151-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:41:40.223-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.222-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:41:40.224-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.224-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:41:40.225-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.225-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:41:40.226-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.226-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:41:40.226-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:41:40.226-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:41:40.227-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:44:45.185-0300] {processor.py:186} INFO - Started process (PID=124437) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:44:45.186-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:44:45.187-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.187-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:44:45.202-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:44:45.271-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.271-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:44:45.278-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.277-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:44:45.278-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.278-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:44:45.278-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.278-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:44:45.279-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.279-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:44:45.284-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.284-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:44:45.284-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.284-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:44:45.285-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.285-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:44:45.285-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.285-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:44:45.525-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.523-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:44:45.526-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.525-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:44:45.527-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.526-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:44:45.528-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.527-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:44:45.528-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:44:45.528-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:44:45.529-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:48:55.490-0300] {processor.py:186} INFO - Started process (PID=128351) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:48:55.491-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:48:55.492-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.492-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:48:55.508-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:48:55.585-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.584-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:48:55.592-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.591-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:48:55.592-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.592-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:48:55.592-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.592-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:48:55.593-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.593-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:48:55.600-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.599-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:48:55.600-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.600-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:48:55.601-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.600-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:48:55.601-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.601-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:48:55.772-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.770-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:48:55.773-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.772-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:48:55.774-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.773-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:48:55.775-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.774-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:48:55.775-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:48:55.775-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:48:55.776-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:53:25.730-0300] {processor.py:186} INFO - Started process (PID=132135) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:53:25.732-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:53:25.733-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.733-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:53:25.748-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:53:25.820-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.820-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:53:25.828-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.828-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:53:25.828-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.828-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:53:25.829-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.829-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:53:25.829-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.829-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:53:25.834-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.834-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:53:25.835-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.835-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:53:25.835-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.835-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:53:25.836-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.836-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:53:25.874-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.872-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:53:25.875-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.874-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:53:25.875-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.875-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:53:25.876-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.876-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:53:25.877-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:53:25.877-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:53:25.878-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:57:12.710-0300] {processor.py:186} INFO - Started process (PID=135090) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:57:12.711-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T17:57:12.712-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.712-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:57:12.728-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T17:57:12.805-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.805-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:57:12.813-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.813-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T17:57:12.813-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.813-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T17:57:12.814-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.814-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T17:57:12.815-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.814-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T17:57:12.821-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.820-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T17:57:12.821-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.821-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T17:57:12.821-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.821-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T17:57:12.822-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.822-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T17:57:12.949-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.947-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:57:12.950-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.949-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:57:12.951-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.950-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:57:12.951-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.951-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T17:57:12.952-0300] {logging_mixin.py:190} INFO - [2024-09-08T17:57:12.952-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T17:57:12.953-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:01:03.664-0300] {processor.py:186} INFO - Started process (PID=138164) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:01:03.665-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:01:03.666-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:03.666-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:01:03.682-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:01:03.762-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:03.762-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:01:03.771-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:03.770-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:01:03.772-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:03.771-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:01:03.772-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:03.772-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:01:03.773-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:03.772-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:01:03.778-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:03.778-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:01:03.778-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:03.778-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:01:03.779-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:03.779-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:01:03.779-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:03.779-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:01:04.070-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:04.068-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:01:04.071-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:04.071-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:01:04.072-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:04.072-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:01:04.073-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:04.073-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:01:04.074-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:01:04.074-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:01:04.075-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:04:41.506-0300] {processor.py:186} INFO - Started process (PID=141024) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:04:41.506-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:04:41.507-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.507-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:04:41.522-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:04:41.595-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.595-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:04:41.602-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.602-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:04:41.603-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.603-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:04:41.603-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.603-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:04:41.603-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.603-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:04:41.609-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.609-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:04:41.609-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.609-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:04:41.610-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.609-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:04:41.610-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.610-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:04:41.947-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.946-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:04:41.948-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.948-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:04:41.949-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.949-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:04:41.950-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.950-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:04:41.950-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:04:41.950-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:04:41.951-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:08:59.604-0300] {processor.py:186} INFO - Started process (PID=145293) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:08:59.605-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:08:59.606-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:08:59.606-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:08:59.624-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:08:59.709-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:08:59.709-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:08:59.718-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:08:59.718-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:08:59.719-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:08:59.719-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:08:59.719-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:08:59.719-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:08:59.719-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:08:59.719-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:08:59.725-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:08:59.725-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:08:59.726-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:08:59.726-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:08:59.727-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:08:59.726-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:08:59.727-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:08:59.727-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:09:00.237-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:09:00.135-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:09:00.239-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:09:00.238-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:09:00.239-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:09:00.239-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:09:00.240-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:09:00.240-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:09:00.241-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:09:00.241-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:09:00.242-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:14:02.869-0300] {processor.py:186} INFO - Started process (PID=149764) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:14:02.883-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:14:02.884-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:02.884-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:14:02.901-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:14:02.980-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:02.980-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:14:02.988-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:02.987-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:14:02.988-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:02.988-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:14:02.989-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:02.988-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:14:02.989-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:02.989-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:14:02.996-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:02.995-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:14:03.089-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:02.996-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:14:03.089-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:03.089-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:14:03.090-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:03.090-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:14:03.543-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:03.542-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:14:03.544-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:03.543-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:14:03.545-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:03.545-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:14:03.546-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:03.546-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:14:03.547-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:14:03.546-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:14:03.548-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:17:24.113-0300] {processor.py:186} INFO - Started process (PID=152035) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:17:24.115-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:17:24.117-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.116-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:17:24.133-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:17:24.234-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.234-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:17:24.340-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.339-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:17:24.340-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.340-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:17:24.340-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.340-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:17:24.341-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.341-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:17:24.346-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.346-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:17:24.347-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.346-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:17:24.347-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.347-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:17:24.347-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.347-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:17:24.684-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.683-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:17:24.685-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.685-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:17:24.686-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.686-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:17:24.688-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.688-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:17:24.689-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:17:24.689-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:17:24.690-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:18:52.153-0300] {processor.py:186} INFO - Started process (PID=152692) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:18:52.154-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:18:52.155-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.155-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:18:52.171-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:18:52.339-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.338-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:18:52.347-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.347-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:18:52.347-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.347-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:18:52.348-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.348-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:18:52.348-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.348-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:18:52.354-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.354-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:18:52.355-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.354-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:18:52.355-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.355-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:18:52.355-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.355-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:18:52.649-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.648-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:18:52.650-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.650-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:18:52.652-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.651-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:18:52.653-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.652-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:18:52.653-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:18:52.653-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:18:52.654-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:20:19.774-0300] {processor.py:186} INFO - Started process (PID=153317) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:20:19.775-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:20:19.776-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:19.776-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:20:19.791-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:20:19.958-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:19.958-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:20:19.964-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:19.964-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:20:19.965-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:19.965-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:20:19.965-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:19.965-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:20:19.965-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:19.965-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:20:19.972-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:19.972-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:20:19.973-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:19.973-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:20:19.973-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:19.973-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:20:19.974-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:19.974-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:20:20.302-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:20.300-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:20:20.303-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:20.303-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:20:20.304-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:20.304-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:20:20.305-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:20.304-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:20:20.305-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:20:20.305-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:20:20.306-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:22:28.778-0300] {processor.py:186} INFO - Started process (PID=154788) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:22:28.779-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:22:28.780-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:28.779-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:22:28.797-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:22:28.979-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:28.979-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:22:28.989-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:28.988-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:22:28.989-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:28.989-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:22:28.990-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:28.989-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:22:28.990-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:28.990-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:22:28.996-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:28.995-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:22:28.996-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:28.996-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:22:28.997-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:28.997-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:22:28.998-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:28.998-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:22:29.160-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:29.159-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:22:29.161-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:29.161-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:22:29.162-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:29.162-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:22:29.163-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:29.163-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:22:29.164-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:22:29.164-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:22:29.165-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:24:09.561-0300] {processor.py:186} INFO - Started process (PID=156101) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:24:09.562-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:24:09.564-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:09.563-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:24:09.579-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:24:09.752-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:09.751-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:24:09.761-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:09.760-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:24:09.761-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:09.761-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:24:09.762-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:09.761-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:24:09.762-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:09.762-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:24:09.768-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:09.767-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:24:09.768-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:09.768-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:24:09.768-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:09.768-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:24:09.769-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:09.769-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:24:10.142-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:10.141-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:24:10.143-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:10.143-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:24:10.145-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:10.144-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:24:10.146-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:10.145-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:24:10.146-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:24:10.146-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:24:10.147-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:25:46.026-0300] {processor.py:186} INFO - Started process (PID=156824) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:25:46.027-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:25:46.028-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.028-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:25:46.046-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:25:46.296-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.296-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:25:46.305-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.305-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:25:46.306-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.306-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:25:46.307-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.306-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:25:46.307-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.307-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:25:46.315-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.315-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:25:46.316-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.316-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:25:46.316-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.316-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:25:46.317-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.317-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:25:46.694-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.692-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:25:46.695-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.694-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:25:46.696-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.696-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:25:46.697-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.697-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:25:46.698-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:25:46.698-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:25:46.699-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:28:47.967-0300] {processor.py:186} INFO - Started process (PID=158876) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:28:47.968-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:28:47.969-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:47.969-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:28:47.989-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:28:48.202-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.202-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:28:48.211-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.211-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:28:48.212-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.212-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:28:48.212-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.212-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:28:48.213-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.213-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:28:48.221-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.220-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:28:48.221-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.221-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:28:48.222-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.222-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:28:48.222-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.222-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:28:48.668-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.666-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:28:48.669-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.669-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:28:48.670-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.670-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:28:48.671-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.671-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:28:48.672-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:28:48.672-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:28:48.673-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:30:18.952-0300] {processor.py:186} INFO - Started process (PID=159878) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:30:18.955-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:30:18.956-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:18.956-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:30:18.974-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:30:19.051-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.051-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:30:19.059-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.059-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:30:19.060-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.059-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:30:19.060-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.060-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:30:19.061-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.061-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:30:19.068-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.067-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:30:19.068-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.068-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:30:19.069-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.069-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:30:19.069-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.069-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:30:19.578-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.576-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:30:19.580-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.579-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:30:19.581-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.580-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:30:19.582-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.581-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:30:19.582-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:30:19.582-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:30:19.583-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:31:49.309-0300] {processor.py:186} INFO - Started process (PID=160612) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:31:49.310-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:31:49.311-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.311-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:31:49.326-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:31:49.399-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.399-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:31:49.407-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.406-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:31:49.407-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.407-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:31:49.407-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.407-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:31:49.408-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.408-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:31:49.414-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.414-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:31:49.415-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.415-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:31:49.415-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.415-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:31:49.416-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.415-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:31:49.747-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.745-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:31:49.748-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.747-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:31:49.749-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.749-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:31:49.750-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.750-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:31:49.751-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:31:49.751-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:31:49.753-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:33:50.428-0300] {processor.py:186} INFO - Started process (PID=161752) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:33:50.429-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:33:50.430-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.429-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:33:50.446-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:33:50.525-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.525-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:33:50.533-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.533-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:33:50.534-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.534-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:33:50.534-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.534-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:33:50.535-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.534-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:33:50.540-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.540-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:33:50.541-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.541-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:33:50.541-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.541-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:33:50.542-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.542-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:33:50.610-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.608-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:33:50.611-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.611-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:33:50.612-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.611-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:33:50.613-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.612-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:33:50.613-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:33:50.613-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:33:50.614-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:35:08.703-0300] {processor.py:186} INFO - Started process (PID=162335) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:35:08.704-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:35:08.704-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:08.704-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:35:08.726-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:35:08.808-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:08.808-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:35:08.817-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:08.817-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:35:08.818-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:08.818-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:35:08.818-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:08.818-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:35:08.819-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:08.818-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:35:08.824-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:08.824-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:35:08.824-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:08.824-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:35:08.825-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:08.825-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:35:08.825-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:08.825-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:35:09.046-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:09.045-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:35:09.047-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:09.047-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:35:09.048-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:09.048-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:35:09.049-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:09.049-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:35:09.050-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:35:09.049-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:35:09.050-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:36:25.491-0300] {processor.py:186} INFO - Started process (PID=162896) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:36:25.492-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:36:25.493-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:25.492-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:36:25.508-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:36:25.583-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:25.583-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:36:25.592-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:25.592-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:36:25.592-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:25.592-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:36:25.593-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:25.593-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:36:25.593-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:25.593-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:36:25.599-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:25.599-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:36:25.599-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:25.599-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:36:25.600-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:25.599-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:36:25.600-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:25.600-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:36:26.061-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:26.059-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:36:26.062-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:26.061-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:36:26.063-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:26.062-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:36:26.064-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:26.063-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:36:26.064-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:36:26.064-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:36:26.065-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:37:45.426-0300] {processor.py:186} INFO - Started process (PID=163474) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:37:45.427-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:37:45.428-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.428-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:37:45.443-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:37:45.519-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.519-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:37:45.529-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.529-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:37:45.529-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.529-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:37:45.530-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.530-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:37:45.530-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.530-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:37:45.536-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.535-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:37:45.536-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.536-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:37:45.536-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.536-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:37:45.537-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.537-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:37:45.958-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.956-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:37:45.959-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.958-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:37:45.960-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.959-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:37:45.961-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.960-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:37:45.961-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:37:45.961-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:37:45.962-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:39:08.228-0300] {processor.py:186} INFO - Started process (PID=164197) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:39:08.231-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:39:08.233-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.232-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:39:08.250-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:39:08.331-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.331-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:39:08.339-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.339-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:39:08.339-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.339-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:39:08.340-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.340-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:39:08.340-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.340-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:39:08.348-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.347-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:39:08.348-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.348-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:39:08.349-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.349-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:39:08.349-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.349-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:39:08.810-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.809-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:39:08.811-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.811-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:39:08.812-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.812-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:39:08.814-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.813-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:39:08.814-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:39:08.814-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:39:08.815-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:40:30.487-0300] {processor.py:186} INFO - Started process (PID=164772) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:40:30.487-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:40:30.488-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.488-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:40:30.502-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:40:30.574-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.574-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:40:30.581-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.581-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:40:30.581-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.581-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:40:30.582-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.582-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:40:30.582-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.582-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:40:30.588-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.587-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:40:30.588-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.588-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:40:30.588-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.588-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:40:30.589-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.589-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:40:30.838-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.836-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:40:30.839-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.838-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:40:30.840-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.839-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:40:30.841-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.840-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:40:30.841-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:40:30.841-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:40:30.842-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:41:48.826-0300] {processor.py:186} INFO - Started process (PID=165862) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:41:48.827-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:41:48.828-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:48.828-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:41:48.843-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:41:48.918-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:48.918-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:41:48.926-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:48.926-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:41:48.926-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:48.926-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:41:48.927-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:48.927-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:41:48.927-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:48.927-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:41:48.933-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:48.933-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:41:48.934-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:48.933-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:41:48.934-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:48.934-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:41:48.934-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:48.934-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:41:49.225-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:49.223-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:41:49.226-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:49.225-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:41:49.227-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:49.226-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:41:49.228-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:49.227-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:41:49.228-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:41:49.228-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:41:49.229-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:43:06.969-0300] {processor.py:186} INFO - Started process (PID=167091) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:43:06.971-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:43:06.972-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:06.972-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:43:06.988-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:43:07.069-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.069-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:43:07.078-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.078-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:43:07.078-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.078-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:43:07.079-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.079-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:43:07.079-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.079-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:43:07.085-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.085-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:43:07.085-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.085-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:43:07.086-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.086-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:43:07.086-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.086-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:43:07.504-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.503-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:43:07.506-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.505-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:43:07.509-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.508-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:43:07.510-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.510-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:43:07.511-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:43:07.511-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:43:07.513-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:44:29.152-0300] {processor.py:186} INFO - Started process (PID=167755) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:44:29.152-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:44:29.153-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.153-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:44:29.167-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:44:29.238-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.238-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:44:29.247-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.247-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:44:29.247-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.247-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:44:29.248-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.247-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:44:29.248-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.248-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:44:29.253-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.253-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:44:29.254-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.254-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:44:29.254-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.254-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:44:29.255-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.254-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:44:29.566-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.565-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:44:29.567-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.567-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:44:29.568-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.568-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:44:29.569-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.569-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:44:29.570-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:44:29.570-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:44:29.570-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:45:48.255-0300] {processor.py:186} INFO - Started process (PID=168309) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:45:48.256-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:45:48.257-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.256-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:45:48.271-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:45:48.341-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.341-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:45:48.349-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.349-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:45:48.350-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.349-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:45:48.350-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.350-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:45:48.350-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.350-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:45:48.356-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.355-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:45:48.356-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.356-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:45:48.356-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.356-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:45:48.357-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.357-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:45:48.640-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.639-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:45:48.641-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.641-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:45:48.643-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.642-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:45:48.644-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.643-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:45:48.644-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:45:48.644-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:45:48.645-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:47:02.233-0300] {processor.py:186} INFO - Started process (PID=168843) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:47:02.234-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:47:02.235-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.234-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:47:02.250-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:47:02.320-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.320-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:47:02.328-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.327-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:47:02.328-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.328-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:47:02.329-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.328-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:47:02.329-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.329-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:47:02.334-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.334-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:47:02.335-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.335-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:47:02.335-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.335-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:47:02.335-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.335-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:47:02.511-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.509-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:47:02.512-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.511-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:47:02.513-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.512-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:47:02.513-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.513-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:47:02.514-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:47:02.514-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:47:02.515-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:48:14.013-0300] {processor.py:186} INFO - Started process (PID=169487) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:48:14.013-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:48:14.014-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.014-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:48:14.031-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:48:14.109-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.109-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:48:14.119-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.118-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:48:14.119-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.119-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:48:14.120-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.120-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:48:14.120-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.120-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:48:14.127-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.127-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:48:14.128-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.128-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:48:14.128-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.128-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:48:14.129-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.129-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:48:14.406-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.404-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:48:14.407-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.406-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:48:14.408-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.408-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:48:14.410-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.409-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:48:14.410-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:48:14.410-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:48:14.411-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:49:36.309-0300] {processor.py:186} INFO - Started process (PID=170398) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:49:36.323-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:49:36.324-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.324-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:49:36.340-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:49:36.421-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.420-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:49:36.429-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.429-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:49:36.430-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.430-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:49:36.430-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.430-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:49:36.431-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.431-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:49:36.436-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.436-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:49:36.437-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.436-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:49:36.437-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.437-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:49:36.437-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.437-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:49:36.530-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.529-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:49:36.531-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.531-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:49:36.532-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.532-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:49:36.533-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.533-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:49:36.534-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:49:36.534-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:49:36.534-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:50:50.799-0300] {processor.py:186} INFO - Started process (PID=171201) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:50:50.800-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:50:50.801-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:50.801-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:50:50.817-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:50:50.906-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:50.906-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:50:50.915-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:50.915-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:50:50.916-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:50.916-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:50:50.916-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:50.916-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:50:50.917-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:50.916-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:50:50.927-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:50.927-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:50:50.927-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:50.927-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:50:50.928-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:50.928-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:50:50.928-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:50.928-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:50:51.358-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:51.357-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:50:51.359-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:51.359-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:50:51.360-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:51.360-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:50:51.361-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:51.361-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:50:51.362-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:50:51.362-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:50:51.363-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:52:03.978-0300] {processor.py:186} INFO - Started process (PID=171927) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:52:03.979-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:52:03.980-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:03.980-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:52:04.001-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:52:04.090-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.089-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:52:04.098-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.098-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:52:04.099-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.099-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:52:04.099-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.099-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:52:04.100-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.100-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:52:04.105-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.105-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:52:04.106-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.106-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:52:04.107-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.106-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:52:04.107-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.107-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:52:04.196-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.194-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:52:04.197-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.196-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:52:04.198-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.197-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:52:04.199-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.198-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:52:04.199-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:52:04.199-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:52:04.200-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:53:29.470-0300] {processor.py:186} INFO - Started process (PID=172663) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:53:29.471-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:53:29.471-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:29.471-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:53:29.488-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:53:29.564-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:29.564-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:53:29.574-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:29.574-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:53:29.575-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:29.574-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:53:29.575-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:29.575-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:53:29.575-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:29.575-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:53:29.581-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:29.581-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:53:29.582-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:29.582-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:53:29.582-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:29.582-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:53:29.583-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:29.583-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:53:30.056-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:30.055-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:53:30.057-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:30.057-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:53:30.058-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:30.058-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:53:30.059-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:30.059-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:53:30.060-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:53:30.060-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:53:30.061-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:54:44.119-0300] {processor.py:186} INFO - Started process (PID=173242) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:54:44.120-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:54:44.120-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.120-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:54:44.135-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:54:44.205-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.205-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:54:44.213-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.213-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:54:44.214-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.214-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:54:44.214-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.214-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:54:44.215-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.214-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:54:44.220-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.220-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:54:44.221-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.220-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:54:44.221-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.221-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:54:44.221-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.221-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:54:44.373-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.372-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:54:44.374-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.374-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:54:44.375-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.374-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:54:44.376-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.375-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:54:44.376-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:54:44.376-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:54:44.377-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:55:58.553-0300] {processor.py:186} INFO - Started process (PID=173850) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:55:58.554-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:55:58.555-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.554-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:55:58.571-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:55:58.642-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.642-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:55:58.650-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.650-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:55:58.650-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.650-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:55:58.651-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.650-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:55:58.651-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.651-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:55:58.658-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.658-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:55:58.658-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.658-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:55:58.659-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.659-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:55:58.659-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.659-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:55:58.910-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.908-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:55:58.911-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.910-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:55:58.911-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.911-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:55:58.912-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.912-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:55:58.913-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:55:58.913-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:55:58.913-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:57:17.020-0300] {processor.py:186} INFO - Started process (PID=174481) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:57:17.021-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:57:17.022-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.021-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:57:17.036-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:57:17.106-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.106-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:57:17.114-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.114-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:57:17.115-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.115-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:57:17.115-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.115-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:57:17.115-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.115-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:57:17.121-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.120-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:57:17.121-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.121-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:57:17.122-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.122-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:57:17.122-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.122-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:57:17.266-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.265-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:57:17.267-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.267-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:57:17.268-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.267-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:57:17.269-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.268-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:57:17.269-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:57:17.269-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:57:17.270-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:58:38.330-0300] {processor.py:186} INFO - Started process (PID=175075) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:58:38.331-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T18:58:38.332-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.332-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:58:38.349-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T18:58:38.426-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.426-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:58:38.434-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.434-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T18:58:38.435-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.435-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T18:58:38.436-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.435-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T18:58:38.436-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.436-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T18:58:38.441-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.441-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T18:58:38.442-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.442-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T18:58:38.442-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.442-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T18:58:38.443-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.443-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T18:58:38.828-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.826-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:58:38.829-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.829-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:58:38.830-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.830-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:58:38.831-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.830-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T18:58:38.831-0300] {logging_mixin.py:190} INFO - [2024-09-08T18:58:38.831-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T18:58:38.832-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:00:01.483-0300] {processor.py:186} INFO - Started process (PID=176143) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:00:01.494-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T19:00:01.495-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.495-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:00:01.512-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:00:01.585-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.584-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:00:01.592-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.592-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T19:00:01.593-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.593-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T19:00:01.594-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.593-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T19:00:01.594-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.594-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T19:00:01.600-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.600-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T19:00:01.600-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.600-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T19:00:01.601-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.600-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T19:00:01.601-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.601-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T19:00:01.911-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.910-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:00:01.912-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.912-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:00:01.913-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.913-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:00:01.914-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.914-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:00:01.915-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:00:01.915-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:00:01.916-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:01:24.780-0300] {processor.py:186} INFO - Started process (PID=176839) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:01:24.781-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T19:01:24.782-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:24.782-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:01:24.798-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:01:24.878-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:24.878-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:01:24.887-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:24.887-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T19:01:24.887-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:24.887-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T19:01:24.888-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:24.887-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T19:01:24.888-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:24.888-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T19:01:24.894-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:24.894-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T19:01:24.895-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:24.895-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T19:01:24.895-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:24.895-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T19:01:24.896-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:24.895-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T19:01:25.038-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:25.036-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:01:25.039-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:25.039-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:01:25.040-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:25.040-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:01:25.041-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:25.041-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:01:25.042-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:01:25.042-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:01:25.042-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:02:47.955-0300] {processor.py:186} INFO - Started process (PID=177665) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:02:47.961-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T19:02:47.962-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:47.962-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:02:47.977-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:02:48.055-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.054-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:02:48.062-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.062-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T19:02:48.062-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.062-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T19:02:48.063-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.063-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T19:02:48.063-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.063-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T19:02:48.068-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.068-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T19:02:48.069-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.068-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T19:02:48.069-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.069-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T19:02:48.069-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.069-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T19:02:48.146-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.144-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:02:48.147-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.146-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:02:48.148-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.147-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:02:48.151-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.150-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:02:48.151-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:02:48.151-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:02:48.152-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:04:11.007-0300] {processor.py:186} INFO - Started process (PID=178304) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:04:11.007-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T19:04:11.008-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.008-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:04:11.025-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:04:11.105-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.104-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:04:11.113-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.113-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T19:04:11.113-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.113-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T19:04:11.114-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.113-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T19:04:11.114-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.114-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T19:04:11.122-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.121-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T19:04:11.122-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.122-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T19:04:11.122-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.122-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T19:04:11.123-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.123-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T19:04:11.332-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.330-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:04:11.333-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.332-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:04:11.333-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.333-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:04:11.334-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.334-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:04:11.335-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:04:11.335-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:04:11.336-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:05:34.732-0300] {processor.py:186} INFO - Started process (PID=178979) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:05:34.733-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T19:05:34.734-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:34.734-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:05:34.750-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:05:34.827-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:34.827-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:05:34.835-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:34.835-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T19:05:34.835-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:34.835-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T19:05:34.836-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:34.835-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T19:05:34.836-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:34.836-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T19:05:34.842-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:34.842-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T19:05:34.843-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:34.842-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T19:05:34.843-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:34.843-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T19:05:34.843-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:34.843-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T19:05:35.014-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:35.012-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:05:35.015-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:35.015-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:05:35.016-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:35.016-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:05:35.017-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:35.017-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:05:35.018-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:05:35.017-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:05:35.018-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:06:54.887-0300] {processor.py:186} INFO - Started process (PID=179633) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:06:54.888-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T19:06:54.888-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:54.888-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:06:54.904-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:06:54.982-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:54.981-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:06:54.989-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:54.989-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T19:06:54.990-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:54.990-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T19:06:54.990-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:54.990-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T19:06:54.991-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:54.991-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T19:06:54.997-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:54.997-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T19:06:54.998-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:54.998-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T19:06:54.998-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:54.998-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T19:06:54.999-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:54.999-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T19:06:55.115-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:55.113-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:06:55.116-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:55.115-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:06:55.117-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:55.116-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:06:55.118-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:55.117-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:06:55.119-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:06:55.118-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:06:55.119-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:08:13.697-0300] {processor.py:186} INFO - Started process (PID=180628) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:08:13.698-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T19:08:13.699-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:13.699-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:08:13.715-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:08:13.789-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:13.789-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:08:13.798-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:13.798-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T19:08:13.798-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:13.798-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T19:08:13.799-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:13.799-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T19:08:13.799-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:13.799-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T19:08:13.804-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:13.804-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T19:08:13.805-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:13.805-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T19:08:13.805-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:13.805-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T19:08:13.805-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:13.805-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T19:08:14.306-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:14.305-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:08:14.307-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:14.307-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:08:14.309-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:14.308-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:08:14.310-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:14.309-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:08:14.310-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:08:14.310-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:08:14.311-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:09:34.372-0300] {processor.py:186} INFO - Started process (PID=181535) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:09:34.373-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T19:09:34.373-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.373-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:09:34.387-0300] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:09:34.462-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.462-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:09:34.471-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.470-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T19:09:34.471-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.471-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T19:09:34.471-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.471-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T19:09:34.472-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.472-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T19:09:34.477-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.477-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T19:09:34.478-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.478-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T19:09:34.478-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.478-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T19:09:34.479-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.479-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T19:09:34.808-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.807-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:09:34.809-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.808-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:09:34.810-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.809-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:09:34.811-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.810-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:09:34.811-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:09:34.811-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:09:34.812-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:10:52.993-0300] {processor.py:186} INFO - Started process (PID=182072) to work on /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:10:52.994-0300] {processor.py:914} INFO - Processing file /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2024-09-08T19:10:52.995-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:52.995-0300] {dagbag.py:587} INFO - Filling up the DagBag from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:10:53.010-0300] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
[2024-09-08T19:10:53.089-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.089-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:10:53.099-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.099-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2024-09-08T19:10:53.099-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.099-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2024-09-08T19:10:53.100-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.100-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2024-09-08T19:10:53.100-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.100-0300] {dag.py:3252} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2024-09-08T19:10:53.107-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.106-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2024-09-08T19:10:53.107-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.107-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2024-09-08T19:10:53.108-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.107-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2024-09-08T19:10:53.108-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.108-0300] {dag.py:4156} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2024-09-08T19:10:53.273-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.272-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:10:53.275-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.274-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:10:53.276-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.275-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:10:53.277-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.277-0300] {dagbag.py:697} ERROR - Failed to write serialized DAG: /home/kasten/.local/lib/python3.12/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 685, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-09-08T19:10:53.278-0300] {logging_mixin.py:190} INFO - [2024-09-08T19:10:53.278-0300] {dag.py:3229} INFO - Sync 4 DAGs
[2024-09-08T19:10:53.278-0300] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 707, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 723, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3242, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/kasten/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: dag_tag.name, dag_tag.dag_id
[SQL: INSERT INTO dag_tag (name, dag_id) VALUES (?, ?)]
[parameters: (('dataset-alias', 'dataset_alias_example_alias_consumer'), ('consumer', 'dataset_alias_example_alias_consumer'), ('producer', 'dataset_alias_example_alias_producer'), ('dataset-alias', 'dataset_alias_example_alias_producer'), ('dataset', 'dataset_s3_bucket_consumer'), ('consumer', 'dataset_s3_bucket_consumer'), ('dataset', 'dataset_s3_bucket_producer'), ('producer', 'dataset_s3_bucket_producer'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
